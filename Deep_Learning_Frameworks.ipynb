{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Frameworks",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedssafini/pyTorch/blob/master/Deep_Learning_Frameworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mavSS3fDPelJ",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning II: Deep Learning\n",
        "# Deep Learning Frameworks\n",
        "\n",
        "In this tutorial, we will learn to build neural networks using PyTorch and Skorch. All the code here can be run on Google Colab directly, and results will be displayed in our browser.\n",
        "\n",
        "---\n",
        "\n",
        "To run this tutorial,\n",
        "\n",
        "1. At the top-right of the menu bar, choose *connect to hosted runtime*.\n",
        "2. In the menu, choose *Runtime -> Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzqKR9-uQ6v1",
        "colab_type": "text"
      },
      "source": [
        "Install PyTorch and Skorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy6WrZejQjX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q torch skorch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPFl3AxEQweQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import sklearn\n",
        "import skorch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnfEhtUIRAOP",
        "colab_type": "text"
      },
      "source": [
        "Check if GPU is available on the current machine. For this notebook, the answer should be true.\n",
        "\n",
        "Note this doesn't necessarily mean everything runs on GPU by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjd7eKpcQ_zK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWNp8sRWKY_3",
        "colab_type": "text"
      },
      "source": [
        "## Tensor basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XlWCTddKd7L",
        "colab_type": "text"
      },
      "source": [
        "In deep learning frameworks, data are represented by tensors. Let's review some tensor basics before we go deeper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygv1EKglKhYr",
        "colab_type": "text"
      },
      "source": [
        "We first load a classical image and represent it as a tensor in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W9DeCd_fKr_3",
        "colab": {}
      },
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png -O lenna.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oYhSqAWIL7RL",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "np_image = np.array(Image.open(\"lenna.png\"))\n",
        "image = torch.as_tensor(np_image)\n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ty0bAttdL9EY"
      },
      "source": [
        "By convention\n",
        "- **dimension** refers to an axis of the tensor\n",
        "- **size** refers to the length of axis in the tensor\n",
        "- **index** refers to a specific coordinate in the tensor\n",
        "\n",
        "The above image is a 512x512x3 tensor of `uint8`. The last size `3` corresponds to the RGB channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "blLeqjosL_QA",
        "colab": {}
      },
      "source": [
        "print(image.shape)\n",
        "print(image.ndim)\n",
        "print(image.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eNJWvDLUMBLp"
      },
      "source": [
        "Operations on tensors are similar to their matrix counterparts.\n",
        "\n",
        "Compute the mean value along an axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ts3imnSXMDSd",
        "colab": {}
      },
      "source": [
        "channel_mean = image.float().mean(dim=2)\n",
        "print(channel_mean.shape)\n",
        "plt.imshow(channel_mean, cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L7BG4NTfMGWn"
      },
      "source": [
        "Slice the first half of an axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OKHz1cqHMKf9",
        "colab": {}
      },
      "source": [
        "horizontal_crop = image[:, :256, :]\n",
        "print(horizontal_crop.shape)\n",
        "plt.imshow(horizontal_crop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iSjgNWWKMM23"
      },
      "source": [
        "Transpose (exchange) two axes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "msca9rpIMO-H",
        "colab": {}
      },
      "source": [
        "transposition = image.transpose(0, 1)\n",
        "print(transposition.shape)\n",
        "plt.imshow(transposition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nN6Xu_DZMRG5"
      },
      "source": [
        "Extend a tensor. Repeat the tensor to form a batch of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ie1v_DJSMS_s",
        "colab": {}
      },
      "source": [
        "def plot(data, labels=None, num_sample=5):\n",
        "  n = min(len(data), num_sample)\n",
        "  for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(data[i], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    if labels is not None:\n",
        "      plt.title(labels[i])\n",
        "\n",
        "batch = image.unsqueeze(0).repeat(3, 1, 1, 1)\n",
        "print(batch.shape)\n",
        "plot(batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U58JGQFzMUl4"
      },
      "source": [
        "Reshape a tensor.\n",
        "\n",
        "The tensor is converted into a long thin matrix. This is a common approach if we want to apply transformations over multiple axes.\n",
        "\n",
        "e.g. transformation over all pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jNGmu9hRMWRB",
        "colab": {}
      },
      "source": [
        "flat = image.flatten(0, 1)\n",
        "print(flat.shape)\n",
        "plt.imshow(flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bvg1uaWTCRf",
        "colab_type": "text"
      },
      "source": [
        "## Practice of basic tensor operations and auto-gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtHrl6YKTLV0",
        "colab_type": "text"
      },
      "source": [
        "**1. Softmax on a vector**\n",
        "\n",
        "Assume that $w$ is a vector of size $d$. Our goal is to compute the $\\text{softmax}(w)$, where $\\text{softmax}(w)_i = \\frac{\\exp(w_i)}{\\sum_{k=1}^d \\exp(w_k)}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdeQ4oS0TwvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = torch.tensor([1., 2., 3., 4., 5.])\n",
        "\n",
        "# TO DO:\n",
        "# Compute the softmax function on w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7_UbKZNUKoe",
        "colab_type": "text"
      },
      "source": [
        "**2. KL divergence between two categorical distributions**\n",
        "\n",
        "Assume that $p$ and $q$ are two $d$-dimensional categorical distributions. The goal is to compute the KL divergence $\\text{KL}(q, p) = \\mathbb{E}_q[\\log \\frac{q}{p}] = \\sum_x q(x) \\log \\frac{q(x)}{p(x)}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obOzON-1U7_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = torch.tensor([0.1, 0.2, 0.3, 0.4])\n",
        "q = torch.tensor([0.4, 0.3, 0.2, 0.1])\n",
        "\n",
        "# TO DO:\n",
        "# Compute the KL divergence between q and p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmjS2sdZW7dw",
        "colab_type": "text"
      },
      "source": [
        "**3. Compute the derivative for a function**\n",
        "\n",
        "Consider a function $f(x) = \\exp(x^3 \\sin (\\log x))$. The goal is to compute $f'(2)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE0CzBLCXVFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To DO:\n",
        "# Compute f'(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTSqw4muM7xC",
        "colab_type": "text"
      },
      "source": [
        "## A linear classifier\n",
        "\n",
        "Next, we use a simple linear classifier to illustrate how we can do model training in PyTorch through auto-gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9OOBLiOY1BB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mnqu/mnqu.github.io/master/data/toy_data.train\n",
        "!wget https://raw.githubusercontent.com/mnqu/mnqu.github.io/master/data/toy_data.test\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load the data.\n",
        "data_train = np.loadtxt(\"/content/toy_data.train\")\n",
        "data_test = np.loadtxt(\"/content/toy_data.test\")\n",
        "\n",
        "x_train = torch.Tensor(data_train[:,0:2])\n",
        "y_train = torch.Tensor(data_train[:,2])\n",
        "\n",
        "x_test = torch.Tensor(data_test[:,0:2])\n",
        "y_test = torch.Tensor(data_test[:,2])\n",
        "\n",
        "w = torch.tensor([[0.], [0.]], requires_grad=True)\n",
        "b = torch.tensor(0., requires_grad=True)\n",
        "\n",
        "for epoch in range(100):\n",
        "  # Make the prediction.\n",
        "  pred_train = torch.mm(x_train, w).squeeze_() + b\n",
        "\n",
        "  # Compare the prediction with the ground-truth outputs.\n",
        "  # Compute a scalar loss.\n",
        "  loss = (pred_train - y_train).pow(2).mean()\n",
        "\n",
        "  if epoch != 0:\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  # Compute the gradient for the model parameters.\n",
        "  loss.backward()\n",
        "\n",
        "  # Update model parameters.\n",
        "  w.data = w.data - 0.01 * w.grad\n",
        "  b.data = b.data - 0.01 * b.grad\n",
        "\n",
        "pred_test = torch.mm(x_test, w).squeeze_() + b\n",
        "pred_test = pred_test.ge(0.5).int()\n",
        "y_test = y_test.int()\n",
        "accuracy = torch.eq(pred_test, y_test).sum().float() / y_test.size(0)\n",
        "\n",
        "print(accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwuVVhsqRbGp",
        "colab_type": "text"
      },
      "source": [
        "## A digit recognition classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hGAG7UbRw0-",
        "colab_type": "text"
      },
      "source": [
        "Here we will build a neural network for image classification. We demonstrate with a classical digit recognition dataset, MNIST.\n",
        "\n",
        "First, let's download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8V13Q9QRkY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = torchvision.datasets.MNIST(\"./data\", train=True, download=True)\n",
        "test = torchvision.datasets.MNIST(\"./data\", train=False, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y1kXruIGD5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJjSOqyXGGrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dk0JRz0GW6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfFvFicMGbt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbDvEZHNIWmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image,label=train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Dyvq87IcyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_1BLSdqNoNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a_YCTRhPsqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(image,cmap='gist_yarg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaKY8i-9Ss84",
        "colab_type": "text"
      },
      "source": [
        "`To have some intuition of the dataset, we visualize some samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egUTRNA5S_gQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.labels = [train.classes[target] for target in train.targets]\n",
        "plot(train.data, train.labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQXSiqhdS_It",
        "colab_type": "text"
      },
      "source": [
        "Now we define our models. We start from a simple multi-layer perceptron (MLP) model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToHnu6quUUYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.5):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, images):\n",
        "    x = images.flatten(1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = F.softmax(self.fc2(x), dim=-1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXW7M_JgWdHQ",
        "colab_type": "text"
      },
      "source": [
        "Then we create an instance of the module, and wrap it with Skorch.\n",
        "\n",
        "We train our model on MNIST for 20 epochs. i.e. the dataset is passed through for 20 times during training. By specifying `device=\"cuda\"`, we can enjoy the acceleration from GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4nxm2ibVEW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = MLP(\n",
        "    input_dim=train.data.shape[1] * train.data.shape[2],\n",
        "    hidden_dim=128,\n",
        "    output_dim=len(train.classes))\n",
        "model = skorch.NeuralNetClassifier(mlp, max_epochs=20, lr=0.1, device=\"cuda\")\n",
        "model.fit(train.data / 255.0, train.targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kcCEKMJXYwr",
        "colab_type": "text"
      },
      "source": [
        "The training process will output a table of training loss, validation accuracy and validation loss.\n",
        "\n",
        "The training loss indicates how good training is. The validation accuracy and loss indicates how good the model generalizes to unseen data. Smaller loss and higher accuracy are better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFG284ipX8fr",
        "colab_type": "text"
      },
      "source": [
        "Let's try to investigate the predictions from our model.\n",
        "\n",
        "Looks good, uh?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LNSoOvJYEGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.mlp_predictions = model.predict(test.data / 255.0)\n",
        "plot(test.data, test.mlp_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb33PuLLYTFy",
        "colab_type": "text"
      },
      "source": [
        "Quantitatively, we can evaluate the predictions by the average accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-iM8uxsYk4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sklearn.metrics.accuracy_score(test.targets, test.mlp_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg3vDyr2YueF",
        "colab_type": "text"
      },
      "source": [
        "We can use pickle to load / save a model at any time.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bip_3kAmY3LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"MLP.pkl\", \"wb\") as fout:\n",
        "  pickle.dump(model, fout)\n",
        "with open(\"MLP.pkl\", \"rb\") as fin:\n",
        "  model = pickle.load(fin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yuRqq0-ZK7H",
        "colab_type": "text"
      },
      "source": [
        "## Standard models\n",
        "\n",
        "In many cases, we want to use some off-the-shelf models for our task. `torchvision` has provided us with a bunch of standard models for image related tasks.\n",
        "\n",
        "Here we leverage ResNet-18, the 18-layer version of ResNet. Since MNIST has 10 classes, we override the last fully connected layer to output 10 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEvxTOmBZnBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18 = torchvision.models.resnet18()\n",
        "resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, len(train.classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVYr-2FEbH9P",
        "colab_type": "text"
      },
      "source": [
        "Because ResNet is designed for colored images, we need to convert the B&W images to RGB ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5xhvVEfbWhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.color_data = train.data.unsqueeze(1).expand(-1, 3, -1, -1)\n",
        "test.color_data = test.data.unsqueeze(1).expand(-1, 3, -1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCCXNrEUfDXl",
        "colab_type": "text"
      },
      "source": [
        "Train our ResNet model. This make take several minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnMilF8cfWGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = skorch.NeuralNetClassifier(\n",
        "    resnet18, criterion=torch.nn.CrossEntropyLoss, max_epochs=2, lr=0.1,\n",
        "    device=\"cuda\")\n",
        "model.fit(train.color_data / 255.0, train.targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KVGjdZVNwmg",
        "colab_type": "text"
      },
      "source": [
        "It seems ResNet is much better than MLP. Let's take a look at the samples where ResNet performs better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua0IItH3N8bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "test.resnet_predictions = model.predict(test.color_data / 255.0)\n",
        "indexes = (test.resnet_predictions == test.targets.numpy()) & \\\n",
        "      (test.mlp_predictions != test.targets.numpy())\n",
        "predictions = np.stack([test.resnet_predictions, test.mlp_predictions], axis=-1)\n",
        "plot(test.data[indexes], predictions[indexes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QuoawejPqcB",
        "colab_type": "text"
      },
      "source": [
        "In the plots, the first prediction is from ResNet and the second is from MLP. Generally, such samples are regarded as **hard samples** of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZomzNBiLqN",
        "colab_type": "text"
      },
      "source": [
        "A good news is that parameters of standard models are also available in `torchvision`.\n",
        "\n",
        "Because these parameters are pre-trained on the million-scale ImageNet dataset, they are powerful and may serve as a good initialization for our MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18-eQwAYijhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, len(train.classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B20vHsLzbfRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = skorch.NeuralNetClassifier(\n",
        "    resnet18, criterion=torch.nn.CrossEntropyLoss, max_epochs=2, lr=0.1,\n",
        "    device=\"cuda\")\n",
        "model.fit(train.color_data / 255.0, train.targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r1mNwmkiyFf",
        "colab_type": "text"
      },
      "source": [
        "A full list of standard models can be found at https://pytorch.org/docs/stable/torchvision/models.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-QF2GuJDvpy",
        "colab_type": "text"
      },
      "source": [
        "## Customize models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcrzl3F_QGk4",
        "colab_type": "text"
      },
      "source": [
        "### Loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkzLr5ybDx12",
        "colab_type": "text"
      },
      "source": [
        "**In this section, you are required to modify some code to get the expected results.**\n",
        "\n",
        "Here we will try to customize an MLP regression model.\n",
        "\n",
        "The MLP model contains two linear (aka. fully connected) layers. Like previous classification model, there should be an activation function (e.g. ReLU) between two layers. However, there shouldn't be any activation at the final output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfL7wk1GETVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLPRegressor(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim):\n",
        "    super(MLPRegressor, self).__init__()\n",
        "    # here are parameter definitions\n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "  \n",
        "  def forward(self, images):\n",
        "    # here is the forward function\n",
        "    # torch.rand() is just for surpassing the errors\n",
        "    # comment out this line before writing your code\n",
        "    x = torch.rand((images.shape[0], 1), requires_grad=True, device=\"cuda\")\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CntNKD7JEgn",
        "colab_type": "text"
      },
      "source": [
        "Train our MLP regressor.\n",
        "\n",
        "Hint: Both losses should be under 0.5 if we implement correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAGgl0PBHyjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_regressor = MLPRegressor(\n",
        "    input_dim=train.data.shape[1] * train.data.shape[2],\n",
        "    hidden_dim=128)\n",
        "model = skorch.NeuralNetRegressor(\n",
        "    mlp_regressor, criterion=nn.SmoothL1Loss, max_epochs=50, lr=0.05,\n",
        "    device=\"cuda\")\n",
        "model.fit(train.data / 255.0, train.targets.float().unsqueeze(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmPxEp1bM4-U",
        "colab_type": "text"
      },
      "source": [
        "We round the regression predictions to get the label for each image.\n",
        "\n",
        "The accuracy score is expected to be around 65%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxMWhjNxIG3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.regressor_predictions = model.predict(test.data / 255.0).round()\n",
        "sklearn.metrics.accuracy_score(test.targets, test.regressor_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg4acIjiQIw5",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M6w3h18QgZ_",
        "colab_type": "text"
      },
      "source": [
        "**In this section, you are required to modify some code to get the expected results.**\n",
        "\n",
        "Optimizer are crucial to training speed. We may try different optimizer and learning rate combination to achieve best training efficiency. Common optimizers are `SGD`, `RMSprop`, `Adagrad` and `Adam`.\n",
        "\n",
        "What is the minimal epoch to achieve ~96% accuracy? What optimizer and learning rate do you use?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoaVfd1xQh4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "mlp = MLP(\n",
        "    input_dim=train.data.shape[1] * train.data.shape[2],\n",
        "    hidden_dim=128,\n",
        "    output_dim=len(train.classes))\n",
        "model = skorch.NeuralNetClassifier(mlp, optimizer=optim.RMSprop, max_epochs=10,\n",
        "                                   lr=1e-4, device=\"cuda\")\n",
        "model.fit(train.data / 255.0, train.targets)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}